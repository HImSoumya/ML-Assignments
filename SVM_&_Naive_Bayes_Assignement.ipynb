{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Theory Question"
      ],
      "metadata": {
        "id": "xbBtZ-EQLCgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is a Support Vector Machine (SVM), and how does it work?\n",
        "\n",
        "Answer:A Support Vector Machine (SVM) is a supervised learning algorithm used for classification and regression. It works by finding the best boundary, called a hyperplane, that separates different classes in the data. We maximize the margin between the classes to improve accuracy and handle new data points effectively."
      ],
      "metadata": {
        "id": "17ZYr9gJLT2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the difference between Hard Margin and Soft Margin SVM.\n",
        "\n",
        "Answer:In Hard Margin SVM, we assume the data is perfectly separable and draw a boundary without allowing any misclassification. In Soft Margin SVM, we allow some errors or overlaps so the model can handle noisy or non-linearly separable data better. This makes Soft Margin more practical in real-world scenarios."
      ],
      "metadata": {
        "id": "AUaWd2t5LfzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the Kernel Trick in SVM? Give one example of a kernel and\n",
        "explain its use case.\n",
        "\n",
        "Answer:The Kernel Trick in SVM allows us to transform data into a higher dimension so it becomes easier to separate with a hyperplane. Instead of computing this transformation directly, we use kernel functions to do it efficiently. For example, the RBF (Radial Basis Function) kernel is useful when data is not linearly separable, as it creates circular decision boundaries around data points."
      ],
      "metadata": {
        "id": "9ckYFW8HLnT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is a Naïve Bayes Classifier, and why is it called “naïve”?\n",
        "\n",
        "Answer:A Naive Bayes Classifier is a probabilistic algorithm based on Bayes’ theorem that is mainly used for classification tasks. It is called “naive” because it assumes all features are independent of each other, which is rarely true in real life. Still, this simple assumption makes the model fast and effective, especially for text classification problems."
      ],
      "metadata": {
        "id": "88bNEfMPLtsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Describe the Gaussian, Multinomial, and Bernoulli Naïve Bayes variants.\n",
        "When would you use each one?\n",
        "\n",
        "Answer:\n",
        "* Gaussian Naive Bayes is used when the features are continuous and follow a normal distribution, like height or weight data.\n",
        "* Multinomial Naive Bayes works well with discrete counts, such as word frequencies in text classification.\n",
        "* Bernoulli Naive Bayes is suitable when features are binary, like whether a word is present or absent in an email for spam detection."
      ],
      "metadata": {
        "id": "hZ-WgLxAL-uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Info:\n",
        "* You can use any suitable datasets like Iris, Breast Cancer, or Wine from\n",
        "sklearn.datasets or a CSV file you have."
      ],
      "metadata": {
        "id": "lTeblMZmMPmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "mO2o2QwOMe2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:   Write a Python program to:\n",
        "* Load the Iris dataset\n",
        "* Train an SVM Classifier with a linear kernel\n",
        "* Print the model's accuracy and support vectors.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "fLzGVY-UMiAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAZ0BazbK-uM",
        "outputId": "757ff88f-b600-4651-bc0f-0b869ffd1c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Support Vectors: [[5.1 3.3 1.7 0.5]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [6.3 2.8 5.1 1.5]]\n"
          ]
        }
      ],
      "source": [
        "# Answer\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(data = iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Support Vectors:\", model.support_vectors_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:  Write a Python program to:\n",
        "* Load the Breast Cancer dataset\n",
        "* Train a Gaussian Naïve Bayes model\n",
        "* Print its classification report including precision, recall, and F1-score.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "N76fAUE0Ouu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "df = pd.DataFrame(data = cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1\n",
        ")\n",
        "\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=cancer.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bClz-H93M2FW",
        "outputId": "82182927-5723-42ab-abb7-9c44d66b9b8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.94      0.92      0.93        63\n",
            "      benign       0.95      0.96      0.96       108\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.94      0.94      0.94       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "* Train an SVM Classifier on the Wine dataset using GridSearchCV to find the best\n",
        "C and gamma.\n",
        "* Print the best hyperparameters and accuracy.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "s4aBpsTUPPD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "wine = load_wine()\n",
        "\n",
        "df = pd.DataFrame(data = wine.data, columns=wine.feature_names)\n",
        "df['target'] = wine.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=1\n",
        ")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid.best_params_)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjvb8x-SPBP1",
        "outputId": "ee41249b-b086-48d8-c567-373204cbe820"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Test Accuracy: 0.7592592592592593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "* Train a Naïve Bayes Classifier on a synthetic text dataset (e.g. using\n",
        "sklearn.datasets.fetch_20newsgroups).\n",
        "* Print the model's ROC-AUC score for its predictions.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "rmuG8ip7PsnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "categories = ['rec.sport.hockey', 'sci.space']\n",
        "data = fetch_20newsgroups(subset='all', categories=categories)\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFFr_qD7PlAW",
        "outputId": "95b27ea1-009c-4542-8ae1-542c4a024ac6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9999887177751452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a company that handles\n",
        "email communications.\n",
        "Your task is to automatically classify emails as Spam or Not Spam. The emails may\n",
        "contain:\n",
        "* Text with diverse vocabulary\n",
        "* Potential class imbalance (far more legitimate emails than spam)\n",
        "* Some incomplete or missing data\n",
        "#Explain the approach you would take to:\n",
        "* Preprocess the data (e.g. text vectorization, handling missing data)\n",
        "* Choose and justify an appropriate model (SVM vs. Naïve Bayes)\n",
        "* Address class imbalance\n",
        "* Evaluate the performance of your solution with suitable metrics\n",
        "And explain the business impact of your solution.\n",
        "\n",
        "\n",
        "Answer:To build an email spam classifier, I would first preprocess the data by converting the email text into numerical features using TF-IDF vectorization, which helps capture the importance of words, and handle missing data by removing empty emails or filling missing fields with placeholders. For the model choice, I would prefer Naïve Bayes because it works very well with text data, is fast, and handles high-dimensional sparse features better than SVM for large datasets. Since email datasets usually have far more legitimate emails than spam, I would address the class imbalance by using resampling techniques like SMOTE or by applying class weights in the model. For evaluation, instead of only accuracy, I would use metrics suited for imbalanced data such as precision, recall, F1-score, and ROC-AUC. Finally, the business impact would be significant:\n",
        "\n",
        "* Accurate spam detection protects users from malicious emails.\n",
        "\n",
        "* Reduces the risk of missing important legitimate emails.\n",
        "\n",
        "* Improves user trust and overall experience.\n",
        "\n",
        "* Saves time by filtering junk emails automatically."
      ],
      "metadata": {
        "id": "0niIxPykQZkn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "psQ8bx_qQCOO"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}