{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theory & Practical Questions"
      ],
      "metadata": {
        "id": "MdlfE5cAVI34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "\n",
        "Answer: A Decision Tree is a supervised learning algorithm that helps us make decisions by splitting data into branches based on features. In classification, it works by dividing the dataset into smaller subsets using conditions until we reach leaf nodes that represent class labels. We can think of it as asking a series of yes/no questions that guide us toward the correct category."
      ],
      "metadata": {
        "id": "Xn6sOh6oVRCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "Answer: Gini Impurity and Entropy are measures used to check how mixed the classes are in a dataset. Gini measures the probability of misclassifying an item, while Entropy measures the amount of randomness or disorder in the data. When building a Decision Tree, we aim for splits that reduce impurity the most, so these measures guide us in choosing the best feature to split on."
      ],
      "metadata": {
        "id": "As42fGynViLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "Answer: Pre-pruning means we stop the tree from growing too deep by setting limits like maximum depth or minimum samples per split, which helps us avoid overfitting early. Post-pruning, on the other hand, lets the tree grow fully and then trims back unnecessary branches to simplify it. A key advantage of pre-pruning is saving time and computation, while post-pruning often gives us a more accurate and generalized model."
      ],
      "metadata": {
        "id": "ENrPuP3KVxgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "Answer: Information Gain measures how much uncertainty or impurity is reduced when we split the data using a particular feature. It compares the entropy before the split and after the split, and the higher the gain, the better the feature is at separating the classes. It is important because it helps us choose the most informative feature, leading to a more accurate and efficient Decision Tree."
      ],
      "metadata": {
        "id": "4v3lL1F8WA--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "Answer: Decision Trees are widely used in areas like medical diagnosis, credit risk assessment, fraud detection, and customer segmentation. Their main advantage is that they are easy to understand, interpret, and visualize. However, they can easily overfit the data and may not perform well when the dataset is very large or noisy unless we use techniques like pruning."
      ],
      "metadata": {
        "id": "kmAg4LVrWNfI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCYI2z1yVhAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Info:\n",
        "  * Iris Dataset for classification tasks (sklearn.datasets.load_iris() or\n",
        "provided CSV).\n",
        "  * Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV)."
      ],
      "metadata": {
        "id": "udkhg3AMWuI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:   Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier using the Gini criterion\n",
        "* Print the modelâ€™s accuracy and feature importances\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "CksBIfPzW7DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion='gini')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(\"Feature Importances:\", classifier.feature_importances_)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "binMFkdoW1Rk",
        "outputId": "8d317ae4-8cc2-4c37-851c-e40af75c2e18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9555555555555556\n",
            "Feature Importances: [0.02146947 0.02146947 0.57196476 0.38509631]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:  Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "* fully-grown tree.\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "vJV2IoRrYscA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "classifier_limited = DecisionTreeClassifier(max_depth=3)\n",
        "classifier_limited.fit(X_train, y_train)\n",
        "y_pred_limited = classifier_limited.predict(X_test)\n",
        "acc_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "classifier_full = DecisionTreeClassifier()\n",
        "classifier_full.fit(X_train, y_train)\n",
        "y_pred_full = classifier_full.predict(X_test)\n",
        "acc_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "print(f\"Accuracy with max_depth=3: {acc_limited}\")\n",
        "print(f\"Accuracy with fully grown tree: {acc_full}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esLRmKLdXQcO",
        "outputId": "a8dd4127-56fd-4e5e-d42b-200e53d6a6fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=3: 0.9555555555555556\n",
            "Accuracy with fully grown tree: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "* Load the California Housing dataset from sklearn\n",
        "* Train a Decision Tree Regressor\n",
        "* Print the Mean Squared Error (MSE) and feature importances\n",
        "*(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "KdkQeWnxZisH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df['target'] = housing.target\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(\"Feature Importances:\", regressor.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc5zcIZHZAWu",
        "outputId": "3193f0e3-6f7e-40ad-b49f-9bc15ebd3400"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.48688516601820087\n",
            "Feature Importances: [0.51029809 0.05208805 0.02900928 0.0266508  0.02703983 0.13941315\n",
            " 0.1091124  0.10638838]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "* Load the Iris Dataset\n",
        "* Tune the Decision Treeâ€™s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "* Print the best parameters and the resulting model accuracy\n",
        "* (Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "yUHtcPwBaKAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with Best Parameters: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdN-KW1XZ5Jd",
        "outputId": "52a5e464-7fb8-419d-d0d6-888cae071621"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
            "Model Accuracy with Best Parameters: 0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine youâ€™re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "* Handle the missing values\n",
        "* Encode the categorical features\n",
        "* Train a Decision Tree model\n",
        "* Tune its hyperparameters\n",
        "* Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "Answer:\n",
        "* Handle Missing Values: For numerical features, we can use mean or median imputation, and for categorical features, we can use the most frequent category to fill missing values.\n",
        "* Encode Categorical Features: Apply One-Hot Encoding or Label Encoding so that the Decision Tree can understand categorical data.\n",
        "* Train the Decision Tree: Split the dataset into training and testing sets, then train a Decision Tree model on the training data.\n",
        "* Tune Hyperparameters: Use GridSearchCV or RandomizedSearchCV to find the best values for parameters like max_depth, min_samples_split, and criterion.\n",
        "* Evaluate the Model: Check performance using metrics like accuracy, precision, recall, F1-score, and ROC-AUC to ensure reliability.\n",
        "* This model can help healthcare professionals predict diseases early, identify high-risk patients, and support better decision-making. It reduces manual workload, improves efficiency, and ultimately leads to better patient outcomes and cost savings for the company."
      ],
      "metadata": {
        "id": "lHMiJpT7auV3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fix-fZXnakRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}