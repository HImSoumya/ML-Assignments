{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theory & Practical Questions"
      ],
      "metadata": {
        "id": "nuCpBW4E9jrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Answer: Logistic Regression is a statistical method we use for predicting categorical outcomes, especially binary ones like yes/no or 0/1. Unlike Linear Regression, which predicts continuous values, Logistic Regression applies the sigmoid function to output probabilities between 0 and 1, making it suitable for classification problems."
      ],
      "metadata": {
        "id": "iyZBPVr79y7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "Answer: In Logistic Regression, we use the Sigmoid function to transform the linear combination of inputs into a value between 0 and 1. This output represents the probability of a data point belonging to a certain class, helping us make clear classification decisions."
      ],
      "metadata": {
        "id": "ZsVQl-gO-P5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Answer: Regularization in Logistic Regression is a technique we use to prevent overfitting by adding a penalty term to the loss function. It helps keep the model simpler by controlling large coefficient values, which improves generalization to new, unseen data."
      ],
      "metadata": {
        "id": "aWvgEEwD-XNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "Answer: Common evaluation metrics for classification models include the Confusion Matrix, Accuracy, Misclassification Rate, Precision, Recall, F1-Score, and F-Beta Score. We use these metrics to evaluate various aspects of performance like how well the model predicts each class, balances false positives and false negatives, and performs under different error priorities helping us choose the most reliable model."
      ],
      "metadata": {
        "id": "T2AtonRM-hFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "3gM6_-Uj_Pg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn (Breast Cancer dataset)\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# Create a DataFrame from the dataset\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Create and train Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear',max_iter=1000)  # max_iter increased to ensure convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ukkk5J-DLf",
        "outputId": "35f5da26-7ad9-4f07-9da9-fdb1f802f665"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:  Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "GPMhZtbjAHAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer:\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn (Breast Cancer dataset)\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# Create a DataFrame from the dataset\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Create Logistic Regression model with L2 regularization (default)\n",
        "model = LogisticRegression(solver='liblinear',penalty='l2', max_iter=1000)  # L2 = Ridge regularization\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coeff:\", model.coef_)\n",
        "print(\"Intercept:\", model.intercept_)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print accuracy\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH-IWlNC_2_q",
        "outputId": "471397a6-ad55-4db7-9177-c67ce5905062"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coeff: [[ 1.82137734  0.07112385 -0.12306166  0.00587456 -0.07595978 -0.32257247\n",
            "  -0.49620872 -0.22286157 -0.11884256 -0.01391574  0.07814557  0.48484736\n",
            "   0.34149697 -0.07132055 -0.01143128 -0.04997087 -0.10056425 -0.03328301\n",
            "  -0.03276574 -0.00328304  1.82550882 -0.23308136 -0.15962553 -0.02971517\n",
            "  -0.13358016 -0.87022834 -1.22100716 -0.41859203 -0.31544016 -0.06521608]]\n",
            "Intercept: [0.3402689]\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "8eSPLeqWAgeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load a multiclass dataset from sklearn (Iris dataset)\n",
        "data = datasets.load_iris()\n",
        "\n",
        "# Create a DataFrame from the dataset\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model for multiclass classification (One-vs-Rest)\n",
        "model = LogisticRegression(solver='liblinear',multi_class='ovr', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t1C60eTAZHJ",
        "outputId": "1a8dc1bb-0d08-4930-9ebb-4bf9ec64c7b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "pC74PF6wA8EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn (Breast Cancer dataset)\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Create Logistic Regression model\n",
        "log_reg = LogisticRegression(solver='liblinear',max_iter=1000)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],       # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],       # Regularization type\n",
        "    'solver': ['liblinear']        # Supports both l1 and l2\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict on test set using best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print validation accuracy\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ221hsvA0sI",
        "outputId": "d22cf7bf-218e-464f-c5a5-e3d16a919be5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Validation Accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "(Use Dataset from sklearn package)\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "is0Z3uyoBPc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn (Breast Cancer dataset)\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Logistic Regression without scaling\n",
        "model_no_scaling = LogisticRegression(solver='liblinear',max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Logistic Regression with scaling\n",
        "model_scaling = LogisticRegression(solver='liblinear',max_iter=1000)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy without Scaling:\", accuracy_no_scaling)\n",
        "print(\"Accuracy with Scaling:\", accuracy_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n8sc1edBGQ3",
        "outputId": "e9f8ab2f-d3aa-4476-c6c6-a2b5c17000e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 0.956140350877193\n",
            "Accuracy with Scaling: 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "\n",
        "Answer:f we get this kind of imbalanced dataset, first we would clean the data and remove or fix any missing values. Since only 5% of customers respond, we would balance the data by either adding more samples of the smaller class oversampling or reducing the bigger class undersampling. We would also scale the features so the model can learn better. Then we would train a Logistic Regression model and try different values of C and penalty to see which works best. For checking the model, we would not only look at accuracy but also Precision, Recall, F1-Score, and ROC-AUC so we know how well it is finding the customers who respond."
      ],
      "metadata": {
        "id": "7VkGQ60lBm2J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2UXTRp-BXuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}